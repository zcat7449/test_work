######################## Filebeat Configuration ############################

filebeat.prospectors:

#------------------------------ Log prospector --------------------------------
- input_type: log
  paths:
    - /var/log/messages
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /var/log/messages
    pri: apache2.info
    source: srv-simi-dmarand02
    program: ahache2
    stand: dev
    my_facility: syslog
    my_type: syslog
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true

- input_type: log
  paths:
    - /var/log/messages
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /var/log/messages
    pri: apache2.info
    source: srv-simi-dmarand02
    program: ahache2
    stand: dev
    my_facility: syslog
    my_type: syslog
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true


- input_type: log
  paths:
    - /opt/tomcat/logs/catalina.*.log
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /opt/tomcat/logs/catalina.yyyy-mm-dd.log
    pri: apache2.info
    source: srv-simi-dmarand02
    program: apache2
    stand: dev
    my_facility: tomcat
    my_type: catalina.log
  multiline:
    match: after
    negate: true
    pattern: ^([0-9]{4}-[0-9]{2}-[0-9]{2})|([J|F|M|A|M|S|O|N|D][a-z]{2} [0-9]{1,2}, [0-9]{2})
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true

- input_type: log
  paths:
    - /var/log/tomcat/Simi2Soap/events.txt
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /var/log/tomcat/Simi2Soap/events.txt
    pri: apache2.info
    source: srv-simi-dmarand02
    program: apache2
    stand: dev
    my_facility: Simi2Soap
    my_type: events.txt
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true

- input_type: log
  paths:
    - /opt/tomcat/logs/EventProcessor/error_handling_events.txt
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /opt/tomcat/logs/EventProcessor/error_handling_events.txt
    pri: apache2.info
    source: srv-simi-dmarand02
    program: apache2
    stand: dev
    my_facility: EventProcessor
    my_type: error_handling_events.txt
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true

- input_type: log
  paths:
    - /opt/tomcat/logs/EventProcessor/events_success_handled.txt
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /opt/tomcat/logs/EventProcessor/events_success_handled.txt
    pri: apache2.info
    source: srv-simi-dmarand02
    program: apache2
    stand: dev
    my_facility: EventProcessor
    my_type: events_success_handled.txt
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true

- input_type: log
  paths:
    - /opt/tomcat/logs/EventProcessor/events.txt
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /opt/tomcat/logs/EventProcessor/events.txt
    pri: apache2.info
    source: srv-simi-dmarand02
    program: apache2
    stand: dev
    my_facility: EventProcessor
    my_type: events.txt
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true

- input_type: log
  paths:
    - /opt/tomcat/logs/EventProcessor/log.txt
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /opt/tomcat/logs/EventProcessor/log.txt
    pri: apache2.info
    source: srv-simi-dmarand02
    program: apache2
    stand: dev
    my_facility: EventProcessor
    my_type: log.txt
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true

- input_type: log
  paths:
    - /opt/tomcat/logs/EventProcessor/performance.txt
  tags: "simi"
  fields:
    product: simi
    facility: marand
    filename: /opt/tomcat/logs/EventProcessor/performance.txt
    pri: apache2.info
    source: srv-simi-dmarand02
    program: apache2
    stand: dev
    my_facility: EventProcessor
    my_type: performance.txt
  fields_under_root: true
  harvester_buffer_size: 16384
  max_bytes: 10485760
  backoff: 1s
  max_backoff: 10s
  backoff_factor: 2
  harvester_limit: 0
  close_inactive: 5m
  close_renamed: true
  close_removed: true
  enabled: true

#================================ General ======================================

# The name of the shipper that publishes the network data. It can be used to group
# all the transactions sent by a single shipper in the web interface.
# If this options is not defined, the hostname is used.
#name:

# The tags of the shipper are included in their own field with each
# transaction published. Tags make it easy to group servers by different
# logical properties.
#tags: ["service-X", "web-tier"]

# Optional fields that you can specify to add additional information to the
# output. Fields can be scalar values, arrays, dictionaries, or any nested
# combination of these.
#fields:
#  env: staging

# If this option is set to true, the custom fields are stored as top-level
# fields in the output document instead of being grouped under a fields
# sub-dictionary. Default is false.
#fields_under_root: false

# Internal queue size for single events in processing pipeline
#queue_size: 1000

# The internal queue size for bulk events in the processing pipeline.
# Do not modify this value.
#bulk_queue_size: 0

# Sets the maximum number of CPUs that can be executing simultaneously. The
# default is the number of logical CPUs available in the system.
#max_procs:

#================================ Processors ===================================

# Processors are used to reduce the number of fields in the exported event or to
# enhance the event with external metadata. This section defines a list of
# processors that are applied one by one and the first one receives the initial
# event:
#
#   event -> filter1 -> event1 -> filter2 ->event2 ...
#
# The supported processors are drop_fields, drop_event, include_fields, and
# add_cloud_metadata.
#
# For example, you can use the following processors to keep the fields that
# contain CPU load percentages, but remove the fields that contain CPU ticks
# values:
#
#processors:
#- include_fields:
#    fields: ["cpu"]
#- drop_fields:
#    fields: ["cpu.user", "cpu.system"]
#
# The following example drops the events that have the HTTP response code 200:
#
#processors:
#- drop_event:
#    when:
#       equals:
#           http.code: 200
#
# The following example enriches each event with metadata from the cloud
# provider about the host machine. It works on EC2, GCE, and DigitalOcean.
#
#processors:
#- add_cloud_metadata:
#

#================================ Outputs ======================================

# Configure what outputs to use when sending the data collected by the beat.
# Multiple outputs may be used.

#------------------------------- Kafka output ----------------------------------
output.kafka:
  enabled: true
  hosts: ["10.0.28.121:9092","10.0.28.122:9092","10.0.28.123:9092"]
  topic: "test"
  worker: 1
  max_retries: 3
  bulk_max_size: 2048
  timeout: 30s
  broker_timeout: 10s
  channel_buffer_size: 256
  keep_alive: 0
  compression: none
  max_message_bytes: 1000000
  required_acks: 1
#  flush_interval: 1s
  client_id: beats

#============================== Dashboards =====================================
dashboards.enabled: false

#================================ Logging ======================================
# There are three options for the log output: syslog, file, stderr.
# Under Windows systems, the log files are per default sent to the file output,
# under all other system per default to syslog.

# Sets log level. The default log level is info.
# Available log levels are: critical, error, warning, info, debug
logging.level: error

# Enable debug output for selected components. To enable all selectors use ["*"]
# Other available selectors are "beat", "publish", "service"
# Multiple selectors can be chained.
#logging.selectors: [ ]

# Send all logging output to syslog. The default is false.
#logging.to_syslog: true

# If enabled, filebeat periodically logs its internal metrics that have changed
# in the last period. For each metric that changed, the delta from the value at
# the beginning of the period is logged. Also, the total values for
# all non-zero internal metrics are logged on shutdown. The default is true.
#logging.metrics.enabled: true

# The period after which to log the internal metrics. The default is 30s.
#logging.metrics.period: 30s

# Logging to rotating files files. Set logging.to_files to false to disable logging to
# files.
logging.to_files: true
logging.files:
  # Configure the path where the logs are written. The default is the logs directory
  # under the home path (the binary location).
  path: /var/log/filebeat

  # The name of the files where the logs are written to.
  name: filebeat

  #Configure log file size limit. If limit is reached, log file will be
  # automatically rotated
  rotateeverybytes: 10485760 # = 10MB

  # Number of rotated log files to keep. Oldest files will be deleted first.
  keepfiles: 7
